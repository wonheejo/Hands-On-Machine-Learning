{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['t-shirt/top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'coat'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(100, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation = 'relu'),\n",
    "    keras.layers.Dense(100, activation = 'relu'),\n",
    "    keras.layers.Dense(10, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x652717e48>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x652724908>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x652724b70>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x638a6bf98>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_3'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('dense_3') is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "                 optimizer='sgd',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "55000/55000 [==============================] - 4s 76us/sample - loss: 0.7230 - accuracy: 0.7613 - val_loss: 0.5031 - val_accuracy: 0.8298\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 4s 69us/sample - loss: 0.4871 - accuracy: 0.8300 - val_loss: 0.4843 - val_accuracy: 0.8276\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.4416 - accuracy: 0.8458 - val_loss: 0.4346 - val_accuracy: 0.8504\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.4138 - accuracy: 0.8539 - val_loss: 0.4143 - val_accuracy: 0.8534\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.3937 - accuracy: 0.8616 - val_loss: 0.3858 - val_accuracy: 0.8698\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.3771 - accuracy: 0.8662 - val_loss: 0.3768 - val_accuracy: 0.8688\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.3627 - accuracy: 0.8712 - val_loss: 0.3758 - val_accuracy: 0.8684\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.3529 - accuracy: 0.8744 - val_loss: 0.3680 - val_accuracy: 0.8696\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.3432 - accuracy: 0.8777 - val_loss: 0.3513 - val_accuracy: 0.8766\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.3334 - accuracy: 0.8816 - val_loss: 0.3514 - val_accuracy: 0.8802\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 4s 72us/sample - loss: 0.3245 - accuracy: 0.8843 - val_loss: 0.3571 - val_accuracy: 0.8700\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 4s 76us/sample - loss: 0.3175 - accuracy: 0.8867 - val_loss: 0.3496 - val_accuracy: 0.8720\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 4s 74us/sample - loss: 0.3089 - accuracy: 0.8901 - val_loss: 0.3381 - val_accuracy: 0.8828\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 4s 74us/sample - loss: 0.3019 - accuracy: 0.8917 - val_loss: 0.3205 - val_accuracy: 0.8860\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 4s 76us/sample - loss: 0.2969 - accuracy: 0.8924 - val_loss: 0.3298 - val_accuracy: 0.8838\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 4s 74us/sample - loss: 0.2903 - accuracy: 0.8948 - val_loss: 0.3231 - val_accuracy: 0.8852\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 4s 76us/sample - loss: 0.2847 - accuracy: 0.8975 - val_loss: 0.3141 - val_accuracy: 0.8880\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 4s 74us/sample - loss: 0.2792 - accuracy: 0.8990 - val_loss: 0.3402 - val_accuracy: 0.8760\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 4s 75us/sample - loss: 0.2736 - accuracy: 0.9018 - val_loss: 0.3110 - val_accuracy: 0.8876\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 4s 75us/sample - loss: 0.2683 - accuracy: 0.9025 - val_loss: 0.3107 - val_accuracy: 0.8916\n",
      "Epoch 21/30\n",
      "55000/55000 [==============================] - 4s 75us/sample - loss: 0.2633 - accuracy: 0.9044 - val_loss: 0.3166 - val_accuracy: 0.8874\n",
      "Epoch 22/30\n",
      "55000/55000 [==============================] - 4s 77us/sample - loss: 0.2591 - accuracy: 0.9066 - val_loss: 0.3566 - val_accuracy: 0.8676\n",
      "Epoch 23/30\n",
      "55000/55000 [==============================] - 4s 74us/sample - loss: 0.2548 - accuracy: 0.9072 - val_loss: 0.3095 - val_accuracy: 0.8904\n",
      "Epoch 24/30\n",
      "55000/55000 [==============================] - 4s 73us/sample - loss: 0.2505 - accuracy: 0.9098 - val_loss: 0.3058 - val_accuracy: 0.8942\n",
      "Epoch 25/30\n",
      "55000/55000 [==============================] - 4s 74us/sample - loss: 0.2457 - accuracy: 0.9114 - val_loss: 0.3300 - val_accuracy: 0.8800\n",
      "Epoch 26/30\n",
      "55000/55000 [==============================] - 4s 77us/sample - loss: 0.2418 - accuracy: 0.9131 - val_loss: 0.2983 - val_accuracy: 0.8966\n",
      "Epoch 27/30\n",
      "55000/55000 [==============================] - 4s 73us/sample - loss: 0.2375 - accuracy: 0.9145 - val_loss: 0.3114 - val_accuracy: 0.8908\n",
      "Epoch 28/30\n",
      "55000/55000 [==============================] - 4s 74us/sample - loss: 0.2340 - accuracy: 0.9157 - val_loss: 0.2973 - val_accuracy: 0.8936\n",
      "Epoch 29/30\n",
      "55000/55000 [==============================] - 4s 76us/sample - loss: 0.2304 - accuracy: 0.9167 - val_loss: 0.2984 - val_accuracy: 0.8930\n",
      "Epoch 30/30\n",
      "55000/55000 [==============================] - 4s 74us/sample - loss: 0.2269 - accuracy: 0.9176 - val_loss: 0.3222 - val_accuracy: 0.8838\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0 - 1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 31us/sample - loss: 65.5789 - accuracy: 0.8495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[65.5789458267212, 0.8495]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ankle boot', 'pullover', 'trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new = y_test[:3]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state = 42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation = 'relu', input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.4248 - val_loss: 0.3956\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4219 - val_loss: 0.3926\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4191 - val_loss: 0.3905\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4166 - val_loss: 0.3872\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4143 - val_loss: 0.3842\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4122 - val_loss: 0.3840\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4101 - val_loss: 0.3809\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4083 - val_loss: 0.3786\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4065 - val_loss: 0.3785\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4048 - val_loss: 0.3757\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4033 - val_loss: 0.3742\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4018 - val_loss: 0.3729\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4004 - val_loss: 0.3718\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3991 - val_loss: 0.3708\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3977 - val_loss: 0.3808\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3966 - val_loss: 0.3689\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3956 - val_loss: 0.3675\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3943 - val_loss: 0.3712\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3931 - val_loss: 0.3658\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.3920 - val_loss: 0.3685\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'mean_squared_error', optimizer = optimizer)\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 17us/sample - loss: 0.3897\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:3] # pretend these are new instances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4342409],\n",
       "       [1.8147109],\n",
       "       [3.3924901]], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0.3, 0.45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:]) # Input object\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_) # Dense layer with 30 neurons, input_ is called which passes it\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1) # Dense layer with 30 neurons, hidden1 is called whic passes it to the next\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 30)           270         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 30)           930         dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 38)           0           input_3[0][0]                    \n",
      "                                                                 dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 1)            39          concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 1.8737 - val_loss: 3.0492\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.6683 - val_loss: 1.1377\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.6017 - val_loss: 0.5548\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.5638 - val_loss: 0.6451\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.5383 - val_loss: 0.7438\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.5208 - val_loss: 0.5584\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.5023 - val_loss: 0.5218\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4891 - val_loss: 0.4561\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4767 - val_loss: 0.5383\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4678 - val_loss: 0.4714\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4592 - val_loss: 0.4396\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4515 - val_loss: 0.4448\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4456 - val_loss: 0.4485\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4409 - val_loss: 0.4457\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4367 - val_loss: 0.4110\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4322 - val_loss: 0.4202\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4283 - val_loss: 0.4730\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4250 - val_loss: 0.4024\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4215 - val_loss: 0.4456\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4190 - val_loss: 0.4067\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 18us/sample - loss: 0.4150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.415037772798723"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name='wide_input')\n",
    "input_B = keras.layers.Input(shape=[6], name='deep_input')\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name='output')(concat)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_a, x_train_b = X_train[:, :5], X_train[:, 2:]\n",
    "x_valid_a, x_valid_b = X_valid[:, :5], X_valid[:, 2:]\n",
    "x_test_a, x_test_b = X_test[:, :5], X_test[:, 2:]\n",
    "x_new_a, x_new_b = x_test_a[:3], x_test_b[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 1.9991 - val_loss: 1.0075\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.7938 - val_loss: 0.6976\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.6527 - val_loss: 0.6241\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.6001 - val_loss: 0.5800\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.5672 - val_loss: 0.5550\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.5425 - val_loss: 0.5244\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.5226 - val_loss: 0.5056\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.5070 - val_loss: 0.4827\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4943 - val_loss: 0.4653\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4840 - val_loss: 0.4554\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4754 - val_loss: 0.4456\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4682 - val_loss: 0.4386\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4622 - val_loss: 0.4321\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4576 - val_loss: 0.4275\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4535 - val_loss: 0.4348\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4499 - val_loss: 0.4196\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4467 - val_loss: 0.4150\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4433 - val_loss: 0.4214\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4410 - val_loss: 0.4171\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4385 - val_loss: 0.4129\n"
     ]
    }
   ],
   "source": [
    "history = model.fit((x_train_a, x_train_b), y_train, epochs=20, validation_data=((x_valid_a, x_valid_b), y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 19us/sample - loss: 0.4291\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate((x_test_a, x_test_b), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict((x_new_a, x_new_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5409853],\n",
       "       [1.9047799],\n",
       "       [3.266901 ]], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name='wide_input')\n",
    "input_B = keras.layers.Input(shape=[6], name='deep_input')\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name='main_output')(concat)\n",
    "aux_output = keras.layers.Dense(1, name='aux_output')(hidden2)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=['mse', 'mse'], loss_weights=[0.9, 0.1], optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 2.2402 - main_output_loss: 1.9199 - aux_output_loss: 5.1157 - val_loss: 3.1638 - val_main_output_loss: 2.6007 - val_aux_output_loss: 8.2193\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 1.0753 - main_output_loss: 0.8518 - aux_output_loss: 3.0880 - val_loss: 1.6513 - val_main_output_loss: 0.9707 - val_aux_output_loss: 7.7702\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.8519 - main_output_loss: 0.7045 - aux_output_loss: 2.1783 - val_loss: 1.3147 - val_main_output_loss: 0.6829 - val_aux_output_loss: 6.9957\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.7540 - main_output_loss: 0.6401 - aux_output_loss: 1.7769 - val_loss: 1.1449 - val_main_output_loss: 0.6071 - val_aux_output_loss: 5.9808\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.6970 - main_output_loss: 0.5988 - aux_output_loss: 1.5806 - val_loss: 0.9858 - val_main_output_loss: 0.5569 - val_aux_output_loss: 4.8419\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.6559 - main_output_loss: 0.5660 - aux_output_loss: 1.4645 - val_loss: 0.8750 - val_main_output_loss: 0.5279 - val_aux_output_loss: 3.9959\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.6243 - main_output_loss: 0.5395 - aux_output_loss: 1.3887 - val_loss: 0.7820 - val_main_output_loss: 0.5038 - val_aux_output_loss: 3.2834\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.5988 - main_output_loss: 0.5173 - aux_output_loss: 1.3306 - val_loss: 0.7067 - val_main_output_loss: 0.4820 - val_aux_output_loss: 2.7264\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.5781 - main_output_loss: 0.4993 - aux_output_loss: 1.2858 - val_loss: 0.6546 - val_main_output_loss: 0.4686 - val_aux_output_loss: 2.3271\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.5619 - main_output_loss: 0.4855 - aux_output_loss: 1.2491 - val_loss: 0.6138 - val_main_output_loss: 0.4571 - val_aux_output_loss: 2.0222\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.5485 - main_output_loss: 0.4741 - aux_output_loss: 1.2173 - val_loss: 0.5833 - val_main_output_loss: 0.4495 - val_aux_output_loss: 1.7860\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.5375 - main_output_loss: 0.4653 - aux_output_loss: 1.1885 - val_loss: 0.5595 - val_main_output_loss: 0.4434 - val_aux_output_loss: 1.6030\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.5290 - main_output_loss: 0.4585 - aux_output_loss: 1.1624 - val_loss: 0.5425 - val_main_output_loss: 0.4399 - val_aux_output_loss: 1.4641\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.5220 - main_output_loss: 0.4537 - aux_output_loss: 1.1389 - val_loss: 0.5322 - val_main_output_loss: 0.4403 - val_aux_output_loss: 1.3580\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.5159 - main_output_loss: 0.4492 - aux_output_loss: 1.1151 - val_loss: 0.5338 - val_main_output_loss: 0.4506 - val_aux_output_loss: 1.2806\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.5108 - main_output_loss: 0.4460 - aux_output_loss: 1.0944 - val_loss: 0.5214 - val_main_output_loss: 0.4446 - val_aux_output_loss: 1.2105\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.5069 - main_output_loss: 0.4439 - aux_output_loss: 1.0731 - val_loss: 0.5057 - val_main_output_loss: 0.4340 - val_aux_output_loss: 1.1496\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.5024 - main_output_loss: 0.4412 - aux_output_loss: 1.0535 - val_loss: 0.5099 - val_main_output_loss: 0.4432 - val_aux_output_loss: 1.1091\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.4990 - main_output_loss: 0.4395 - aux_output_loss: 1.0344 - val_loss: 0.5057 - val_main_output_loss: 0.4427 - val_aux_output_loss: 1.0710\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.4955 - main_output_loss: 0.4377 - aux_output_loss: 1.0163 - val_loss: 0.5053 - val_main_output_loss: 0.4458 - val_aux_output_loss: 1.0394\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([x_train_a, x_train_b], [y_train, y_train], epochs=20, validation_data=([x_valid_a, x_valid_b], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 22us/sample - loss: 0.4870 - main_output_loss: 0.4305 - aux_output_loss: 0.9978\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_losss, aux_loss = model.evaluate([x_test_a, x_test_b], [y_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_main, y_pred_aux = model.predict([x_new_a, x_new_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3541407],\n",
       "       [2.024794 ],\n",
       "       [3.130018 ]], dtype=float32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.086978 ],\n",
       "       [1.9836444],\n",
       "       [2.4403   ]], dtype=float32)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation = 'relu', input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation = 'relu'),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "11610/11610 [==============================] - 1s 55us/sample - loss: 1.8423 - val_loss: 5.2165\n",
      "Epoch 2/10\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.6876 - val_loss: 0.7732\n",
      "Epoch 3/10\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.5954 - val_loss: 0.5446\n",
      "Epoch 4/10\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.5553 - val_loss: 0.5425\n",
      "Epoch 5/10\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.5268 - val_loss: 0.5539\n",
      "Epoch 6/10\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.5049 - val_loss: 0.4701\n",
      "Epoch 7/10\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4852 - val_loss: 0.4562\n",
      "Epoch 8/10\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4706 - val_loss: 0.4452\n",
      "Epoch 9/10\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4576 - val_loss: 0.4406\n",
      "Epoch 10/10\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4476 - val_loss: 0.4185\n",
      "5160/5160 [==============================] - 0s 15us/sample - loss: 0.4376\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer = opt)\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data = (X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('my_keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.551559 ],\n",
       "       [1.6555369],\n",
       "       [3.0014234]], dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('my_keras_weights.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x63933ce48>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('my_keras_weights.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 1.8423 - val_loss: 5.2165\n",
      "Epoch 2/10\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.6876 - val_loss: 0.7732\n",
      "Epoch 3/10\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.5954 - val_loss: 0.5446\n",
      "Epoch 4/10\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.5553 - val_loss: 0.5425\n",
      "Epoch 5/10\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.5268 - val_loss: 0.5539\n",
      "Epoch 6/10\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.5049 - val_loss: 0.4701\n",
      "Epoch 7/10\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4852 - val_loss: 0.4562\n",
      "Epoch 8/10\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4706 - val_loss: 0.4452\n",
      "Epoch 9/10\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4576 - val_loss: 0.4406\n",
      "Epoch 10/10\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4476 - val_loss: 0.4185\n",
      "5160/5160 [==============================] - 0s 22us/sample - loss: 0.4376\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer=opt)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('my_keras_model.h5', save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid), callbacks=[checkpoint_cb])\n",
    "model = keras.models.load_model('my_keras_model.h5')\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.4385 - val_loss: 0.4287\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4319 - val_loss: 0.4117\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4252 - val_loss: 0.3975\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4199 - val_loss: 0.3943\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4150 - val_loss: 0.3964\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4110 - val_loss: 0.3907\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4070 - val_loss: 0.3823\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4036 - val_loss: 0.3786\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4003 - val_loss: 0.3739\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3973 - val_loss: 0.3724\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3944 - val_loss: 0.3697\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3916 - val_loss: 0.3670\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3892 - val_loss: 0.3638\n",
      "Epoch 14/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3869 - val_loss: 0.3633\n",
      "Epoch 15/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3845 - val_loss: 0.4051\n",
      "Epoch 16/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3826 - val_loss: 0.3662\n",
      "Epoch 17/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3805 - val_loss: 0.3554\n",
      "Epoch 18/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3782 - val_loss: 0.3684\n",
      "Epoch 19/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3762 - val_loss: 0.3523\n",
      "Epoch 20/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3744 - val_loss: 0.3622\n",
      "Epoch 21/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3727 - val_loss: 0.3498\n",
      "Epoch 22/100\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3709 - val_loss: 0.3651\n",
      "Epoch 23/100\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.3694 - val_loss: 0.3538\n",
      "Epoch 24/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3681 - val_loss: 0.3479\n",
      "Epoch 25/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3668 - val_loss: 0.3475\n",
      "Epoch 26/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3654 - val_loss: 0.3483\n",
      "Epoch 27/100\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.3641 - val_loss: 0.3787\n",
      "Epoch 28/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3631 - val_loss: 0.3461\n",
      "Epoch 29/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3618 - val_loss: 0.3709\n",
      "Epoch 30/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3607 - val_loss: 0.3530\n",
      "Epoch 31/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3596 - val_loss: 0.3429\n",
      "Epoch 32/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3586 - val_loss: 0.3441\n",
      "Epoch 33/100\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3577 - val_loss: 0.3534\n",
      "Epoch 34/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3567 - val_loss: 0.3359\n",
      "Epoch 35/100\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.3557 - val_loss: 0.3828\n",
      "Epoch 36/100\n",
      "11610/11610 [==============================] - 1s 64us/sample - loss: 0.3551 - val_loss: 0.3345\n",
      "Epoch 37/100\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3541 - val_loss: 0.3843\n",
      "Epoch 38/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3534 - val_loss: 0.3329\n",
      "Epoch 39/100\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3524 - val_loss: 0.3933\n",
      "Epoch 40/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3522 - val_loss: 0.3314\n",
      "Epoch 41/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3510 - val_loss: 0.3985\n",
      "Epoch 42/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3507 - val_loss: 0.3299\n",
      "Epoch 43/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3498 - val_loss: 0.3466\n",
      "Epoch 44/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3488 - val_loss: 0.3414\n",
      "Epoch 45/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3484 - val_loss: 0.3436\n",
      "Epoch 46/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3479 - val_loss: 0.3289\n",
      "Epoch 47/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3468 - val_loss: 0.3655\n",
      "Epoch 48/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3467 - val_loss: 0.3285\n",
      "Epoch 49/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3461 - val_loss: 0.3964\n",
      "Epoch 50/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3455 - val_loss: 0.3299\n",
      "Epoch 51/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3451 - val_loss: 0.3349\n",
      "Epoch 52/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3446 - val_loss: 0.3328\n",
      "Epoch 53/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3440 - val_loss: 0.3580\n",
      "Epoch 54/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3433 - val_loss: 0.3316\n",
      "Epoch 55/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3429 - val_loss: 0.3252\n",
      "Epoch 56/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3422 - val_loss: 0.3857\n",
      "Epoch 57/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3422 - val_loss: 0.3237\n",
      "Epoch 58/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3414 - val_loss: 0.3387\n",
      "Epoch 59/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3409 - val_loss: 0.3226\n",
      "Epoch 60/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3403 - val_loss: 0.4004\n",
      "Epoch 61/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3406 - val_loss: 0.3220\n",
      "Epoch 62/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3396 - val_loss: 0.3940\n",
      "Epoch 63/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3393 - val_loss: 0.3282\n",
      "Epoch 64/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3391 - val_loss: 0.3584\n",
      "Epoch 65/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3383 - val_loss: 0.3217\n",
      "Epoch 66/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3380 - val_loss: 0.3738\n",
      "Epoch 67/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3378 - val_loss: 0.3397\n",
      "Epoch 68/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3373 - val_loss: 0.3194\n",
      "Epoch 69/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3367 - val_loss: 0.3785\n",
      "Epoch 70/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3368 - val_loss: 0.3205\n",
      "Epoch 71/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3358 - val_loss: 0.3817\n",
      "Epoch 72/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3358 - val_loss: 0.3350\n",
      "Epoch 73/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3350 - val_loss: 0.3332\n",
      "Epoch 74/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3350 - val_loss: 0.3179\n",
      "Epoch 75/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3345 - val_loss: 0.3476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3341 - val_loss: 0.3196\n",
      "Epoch 77/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3338 - val_loss: 0.3608\n",
      "Epoch 78/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3336 - val_loss: 0.3295\n",
      "Epoch 79/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3331 - val_loss: 0.3927\n",
      "Epoch 80/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3332 - val_loss: 0.3167\n",
      "Epoch 81/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3317 - val_loss: 0.3783\n",
      "Epoch 82/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3322 - val_loss: 0.3154\n",
      "Epoch 83/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3315 - val_loss: 0.3538\n",
      "Epoch 84/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3312 - val_loss: 0.3282\n",
      "Epoch 85/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3307 - val_loss: 0.3379\n",
      "Epoch 86/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3306 - val_loss: 0.3163\n",
      "Epoch 87/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3302 - val_loss: 0.3377\n",
      "Epoch 88/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3300 - val_loss: 0.3340\n",
      "Epoch 89/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3295 - val_loss: 0.3158\n",
      "Epoch 90/100\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3294 - val_loss: 0.3519\n",
      "Epoch 91/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3289 - val_loss: 0.3142\n",
      "Epoch 92/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3286 - val_loss: 0.3619\n",
      "Epoch 93/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3282 - val_loss: 0.3270\n",
      "Epoch 94/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3282 - val_loss: 0.4632\n",
      "Epoch 95/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3284 - val_loss: 0.3371\n",
      "Epoch 96/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3275 - val_loss: 0.4659\n",
      "Epoch 97/100\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3278 - val_loss: 0.3156\n",
      "Epoch 98/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3265 - val_loss: 0.3259\n",
      "Epoch 99/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3262 - val_loss: 0.3407\n",
      "Epoch 100/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3264 - val_loss: 0.3176\n",
      "5160/5160 [==============================] - 0s 17us/sample - loss: 0.3271\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer=opt)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[early_stopping_cb])\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print('\\nval/train: {:.2f}'.format(logs['val_loss'] / logs['loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "10112/11610 [=========================>....] - ETA: 0s - loss: 0.3202\n",
      "val/train: 1.16\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3256 - val_loss: 0.3785\n",
      "Epoch 2/10\n",
      "10240/11610 [=========================>....] - ETA: 0s - loss: 0.3245\n",
      "val/train: 0.97\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3257 - val_loss: 0.3145\n",
      "Epoch 3/10\n",
      "10240/11610 [=========================>....] - ETA: 0s - loss: 0.3235\n",
      "val/train: 1.13\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3250 - val_loss: 0.3659\n",
      "Epoch 4/10\n",
      "11392/11610 [============================>.] - ETA: 0s - loss: 0.3255\n",
      "val/train: 0.96\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3250 - val_loss: 0.3119\n",
      "Epoch 5/10\n",
      "10752/11610 [==========================>...] - ETA: 0s - loss: 0.3233\n",
      "val/train: 1.12\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3244 - val_loss: 0.3634\n",
      "Epoch 6/10\n",
      "10368/11610 [=========================>....] - ETA: 0s - loss: 0.3258\n",
      "val/train: 0.98\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3245 - val_loss: 0.3187\n",
      "Epoch 7/10\n",
      "10432/11610 [=========================>....] - ETA: 0s - loss: 0.3257\n",
      "val/train: 0.97\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3240 - val_loss: 0.3147\n",
      "Epoch 8/10\n",
      "10304/11610 [=========================>....] - ETA: 0s - loss: 0.3224\n",
      "val/train: 0.96\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3238 - val_loss: 0.3108\n",
      "Epoch 9/10\n",
      " 9984/11610 [========================>.....] - ETA: 0s - loss: 0.3278\n",
      "val/train: 1.06\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3232 - val_loss: 0.3441\n",
      "Epoch 10/10\n",
      "10144/11610 [=========================>....] - ETA: 0s - loss: 0.3195\n",
      "val/train: 0.96\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3234 - val_loss: 0.3096\n"
     ]
    }
   ],
   "source": [
    "val_train_ratio_callback = PrintValTrainRatioCallback()\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid), callbacks=[val_train_ratio_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape = input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 1.0374 - val_loss: 3.3394\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.5436 - val_loss: 2.5033\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4851 - val_loss: 0.7090\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4501 - val_loss: 0.4999\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4328 - val_loss: 0.4002\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4228 - val_loss: 0.4312\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4165 - val_loss: 0.4030\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4113 - val_loss: 0.3829\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4070 - val_loss: 0.4289\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4042 - val_loss: 0.3795\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4009 - val_loss: 0.3717\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3982 - val_loss: 0.3698\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3958 - val_loss: 0.3677\n",
      "Epoch 14/100\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3939 - val_loss: 0.3699\n",
      "Epoch 15/100\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3912 - val_loss: 0.5933\n",
      "Epoch 16/100\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3917 - val_loss: 0.6508\n",
      "Epoch 17/100\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3902 - val_loss: 0.4027\n",
      "Epoch 18/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3869 - val_loss: 0.3737\n",
      "Epoch 19/100\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3854 - val_loss: 0.4112\n",
      "Epoch 20/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3834 - val_loss: 0.6424\n",
      "Epoch 21/100\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.3848 - val_loss: 0.5161\n",
      "Epoch 22/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3812 - val_loss: 0.7151\n",
      "Epoch 23/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3822 - val_loss: 0.6332\n",
      "5160/5160 [==============================] - 0s 17us/sample - loss: 0.3767\n"
     ]
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100, validation_data = (X_valid, y_valid), callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "mse_test = keras_reg.score(X_test, y_test)\n",
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs = {\n",
    "    'n_hidden' : [0, 1, 2, 3],\n",
    "    'n_neurons' : np.arange(1, 100),\n",
    "    'learning_rate' : reciprocal(3e-4, 3e-2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 3.7147 - val_loss: 1.7484\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 1.2561 - val_loss: 0.8920\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.8183 - val_loss: 0.8955\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.7155 - val_loss: 1.0164\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.6835 - val_loss: 0.7203\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.6597 - val_loss: 0.7317\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.6411 - val_loss: 0.9878\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6337 - val_loss: 0.6067\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6185 - val_loss: 0.5766\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.6079 - val_loss: 0.6042\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.5990 - val_loss: 0.5718\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5896 - val_loss: 0.6978\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.5843 - val_loss: 0.5492\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.5736 - val_loss: 0.8633\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5708 - val_loss: 0.9004\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5695 - val_loss: 0.5483\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.5579 - val_loss: 0.9083\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.5594 - val_loss: 0.7467\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5562 - val_loss: 0.5699\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5517 - val_loss: 0.5162\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5484 - val_loss: 0.5520\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5456 - val_loss: 0.6213\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5428 - val_loss: 0.7424\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5442 - val_loss: 0.5143\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5383 - val_loss: 0.7195\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5400 - val_loss: 0.6246\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5358 - val_loss: 0.7977\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5389 - val_loss: 0.5657\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5354 - val_loss: 0.5828\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.5330 - val_loss: 0.7364\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.5359 - val_loss: 0.5273\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5311 - val_loss: 0.7203\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5344 - val_loss: 0.5174\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.5320 - val_loss: 0.5210\n",
      "3870/3870 [==============================] - 0s 15us/sample - loss: 0.5389\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 4.1775 - val_loss: 26.6904\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 1.3465 - val_loss: 26.5895\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.7954 - val_loss: 26.5060\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.6730 - val_loss: 26.2096\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6361 - val_loss: 25.8393\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6175 - val_loss: 25.4662\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.6039 - val_loss: 25.0417\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.5927 - val_loss: 24.7388\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5827 - val_loss: 24.4034\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.5738 - val_loss: 24.1570\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5659 - val_loss: 23.8076\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.5588 - val_loss: 23.5171\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.5525 - val_loss: 23.4074\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.5469 - val_loss: 23.1692\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5420 - val_loss: 22.9112\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.5374 - val_loss: 22.8855\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5336 - val_loss: 22.7224\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5301 - val_loss: 22.5729\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.5267 - val_loss: 22.2674\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.5239 - val_loss: 22.2567\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.5215 - val_loss: 22.1475\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.5191 - val_loss: 22.0372\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5172 - val_loss: 22.0017\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5152 - val_loss: 21.7231\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.5137 - val_loss: 21.6856\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5122 - val_loss: 21.5166\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5108 - val_loss: 21.5551\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.5097 - val_loss: 21.3247\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5086 - val_loss: 21.3326\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.5077 - val_loss: 21.3844\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.5067 - val_loss: 21.3956\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5061 - val_loss: 21.3089\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5053 - val_loss: 21.1220\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5047 - val_loss: 20.9385\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5042 - val_loss: 20.9245\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.5034 - val_loss: 20.9636\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5032 - val_loss: 20.8398\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.5026 - val_loss: 20.7279\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5020 - val_loss: 20.7399\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.5020 - val_loss: 20.7517\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5017 - val_loss: 20.6950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5015 - val_loss: 20.7167\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5011 - val_loss: 20.7559\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5006 - val_loss: 20.6051\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5005 - val_loss: 20.5465\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5004 - val_loss: 20.4189\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.5002 - val_loss: 20.4583\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5001 - val_loss: 20.4698\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5000 - val_loss: 20.5012\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.4999 - val_loss: 20.4808\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.4996 - val_loss: 20.3964\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4994 - val_loss: 20.4772\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4996 - val_loss: 20.4061\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4993 - val_loss: 20.3412\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4993 - val_loss: 20.2324\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4992 - val_loss: 20.2730\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4991 - val_loss: 20.1780\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.4990 - val_loss: 20.2257\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4990 - val_loss: 20.1979\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4989 - val_loss: 20.1820\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.4988 - val_loss: 20.2586\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.4987 - val_loss: 20.2920\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.4987 - val_loss: 20.2575\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.4987 - val_loss: 20.2629\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.4986 - val_loss: 20.2928\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.4986 - val_loss: 20.4050\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.4986 - val_loss: 20.4165\n",
      "3870/3870 [==============================] - 0s 15us/sample - loss: 0.9919\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 4.4293 - val_loss: 1.8802\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 1.2210 - val_loss: 0.9916\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.7501 - val_loss: 1.0360\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.6554 - val_loss: 0.7230\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.6218 - val_loss: 0.9276\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.6110 - val_loss: 0.7968\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.5992 - val_loss: 0.8219\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5898 - val_loss: 0.9127\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5825 - val_loss: 0.9811\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.5775 - val_loss: 0.9387\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.5738 - val_loss: 0.6648\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5658 - val_loss: 0.7076\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.5628 - val_loss: 0.5322\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.5576 - val_loss: 0.5472\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.5545 - val_loss: 0.5187\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5511 - val_loss: 0.5852\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5472 - val_loss: 0.7402\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5480 - val_loss: 0.5459\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.5439 - val_loss: 0.6136\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5413 - val_loss: 0.7409\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5418 - val_loss: 0.6494\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.5398 - val_loss: 0.6398\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.5384 - val_loss: 0.6480\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5381 - val_loss: 0.5989\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.5365 - val_loss: 0.6098\n",
      "3870/3870 [==============================] - 0s 14us/sample - loss: 0.5401\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 1.7774 - val_loss: 63.4604\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 1.3366 - val_loss: 524.4779\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 8.6598 - val_loss: 1969.0291\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 32.7457 - val_loss: 7501.8861\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 57.8745 - val_loss: 28249.8164\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 344.2066 - val_loss: 113233.6751\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 2693.7935 - val_loss: 447634.2912\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 2309.7430 - val_loss: 1815170.6074\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 7014.1610 - val_loss: 7142170.7999\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 42985.5445 - val_loss: 27692392.7564\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 155988.4084 - val_loss: 108948623.9821\n",
      "3870/3870 [==============================] - 0s 16us/sample - loss: 290464.5328\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 1.4490 - val_loss: 5.6221\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.6193 - val_loss: 15.5115\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.5597 - val_loss: 20.6693\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5316 - val_loss: 19.9996\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.5183 - val_loss: 19.8354\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.5106 - val_loss: 19.5351\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5055 - val_loss: 18.1433\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5051 - val_loss: 18.2889\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.5047 - val_loss: 17.7784\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5028 - val_loss: 18.9972\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5038 - val_loss: 17.2094\n",
      "3870/3870 [==============================] - 0s 14us/sample - loss: 0.9088\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 2.5637 - val_loss: 99.2314\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.8325 - val_loss: 117.8748\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 3.7997 - val_loss: 198.9456\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 2.3015 - val_loss: 304.6343\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 7.2961 - val_loss: 544.5842\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 5.6331 - val_loss: 1000.6067\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 22.4476 - val_loss: 1919.8352\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 45.1861 - val_loss: 3846.0303\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 116.8189 - val_loss: 7081.6727\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 190.7213 - val_loss: 14108.1491\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 164.2118 - val_loss: 27629.3295\n",
      "3870/3870 [==============================] - 0s 14us/sample - loss: 33.3457\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 2.7233 - val_loss: 7.8786\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 1.2013 - val_loss: 1.1881\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.8590 - val_loss: 0.8079\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.7711 - val_loss: 0.7186\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.7270 - val_loss: 0.6870\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6961 - val_loss: 0.6587\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6707 - val_loss: 0.6330\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6488 - val_loss: 0.6232\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6286 - val_loss: 0.6068\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6099 - val_loss: 0.5902\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5924 - val_loss: 0.5695\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5761 - val_loss: 0.5458\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5612 - val_loss: 0.5412\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5467 - val_loss: 0.5174\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5342 - val_loss: 0.5064\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5220 - val_loss: 0.5169\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5109 - val_loss: 0.4840\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5011 - val_loss: 0.4815\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4917 - val_loss: 0.4888\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4828 - val_loss: 0.4756\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4749 - val_loss: 0.4769\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4677 - val_loss: 0.4527\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4609 - val_loss: 0.4526\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4545 - val_loss: 0.4523\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4486 - val_loss: 0.4485\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4433 - val_loss: 0.4361\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4380 - val_loss: 0.4322\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4334 - val_loss: 0.4429\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4290 - val_loss: 0.4276\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4249 - val_loss: 0.4286\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4211 - val_loss: 0.4374\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4176 - val_loss: 0.4350\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4144 - val_loss: 0.4294\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4114 - val_loss: 0.4353\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4086 - val_loss: 0.4240\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4057 - val_loss: 0.4080\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4037 - val_loss: 0.4151\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4012 - val_loss: 0.4203\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3991 - val_loss: 0.4378\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3970 - val_loss: 0.4178\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3951 - val_loss: 0.4110\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3932 - val_loss: 0.4135\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3914 - val_loss: 0.4254\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3896 - val_loss: 0.4107\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3880 - val_loss: 0.4356\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3866 - val_loss: 0.4142\n",
      "3870/3870 [==============================] - 0s 17us/sample - loss: 0.4010\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 109us/sample - loss: 2.2803 - val_loss: 5.3778\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.9437 - val_loss: 5.1596\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.8057 - val_loss: 3.8660\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.7544 - val_loss: 2.7994\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.7220 - val_loss: 2.0150\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6957 - val_loss: 1.5038\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6727 - val_loss: 1.0590\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6522 - val_loss: 0.8233\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.6332 - val_loss: 0.6482\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6161 - val_loss: 0.5885\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5999 - val_loss: 0.5779\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5849 - val_loss: 0.6214\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5713 - val_loss: 0.6718\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5582 - val_loss: 0.7658\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5461 - val_loss: 0.8816\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5351 - val_loss: 0.9527\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5246 - val_loss: 1.0866\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5147 - val_loss: 1.1268\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5057 - val_loss: 1.2202\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4968 - val_loss: 1.3030\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4890 - val_loss: 1.3068\n",
      "3870/3870 [==============================] - 0s 16us/sample - loss: 0.5214\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 2.8740 - val_loss: 6.1228\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 1.1529 - val_loss: 1.6205\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.8046 - val_loss: 0.8508\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.7155 - val_loss: 0.6808\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6748 - val_loss: 0.6417\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6476 - val_loss: 0.6196\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6250 - val_loss: 0.5987\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6048 - val_loss: 0.5802\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5867 - val_loss: 0.5676\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5702 - val_loss: 0.5436\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5550 - val_loss: 0.5280\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5412 - val_loss: 0.5093\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5281 - val_loss: 0.4964\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5163 - val_loss: 0.4861\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5054 - val_loss: 0.4751\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4952 - val_loss: 0.4663\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4860 - val_loss: 0.4559\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4773 - val_loss: 0.4509\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4698 - val_loss: 0.4403\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4626 - val_loss: 0.4367\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4561 - val_loss: 0.4320\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4500 - val_loss: 0.4234\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4444 - val_loss: 0.4170\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4391 - val_loss: 0.4207\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4344 - val_loss: 0.4128\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4301 - val_loss: 0.4135\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4260 - val_loss: 0.4140\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4224 - val_loss: 0.4085\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4190 - val_loss: 0.3981\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4158 - val_loss: 0.4003\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4129 - val_loss: 0.3950\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4105 - val_loss: 0.3952\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4079 - val_loss: 0.3992\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4054 - val_loss: 0.4105\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4036 - val_loss: 0.3931\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4014 - val_loss: 0.3872\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3994 - val_loss: 0.3923\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3981 - val_loss: 0.3957\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3959 - val_loss: 0.4065\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3945 - val_loss: 0.3842\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3929 - val_loss: 0.3829\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3913 - val_loss: 0.3860\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3898 - val_loss: 0.3774\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3883 - val_loss: 0.3972\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3874 - val_loss: 0.3787\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3858 - val_loss: 0.3826\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3847 - val_loss: 0.3815\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3836 - val_loss: 0.3827\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3825 - val_loss: 0.3866\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3814 - val_loss: 0.3735\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3803 - val_loss: 0.3705\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3793 - val_loss: 0.3732\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3783 - val_loss: 0.3738\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3773 - val_loss: 0.3776\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3762 - val_loss: 0.3955\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3753 - val_loss: 0.4067\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3746 - val_loss: 0.3781\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3737 - val_loss: 0.3967\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3729 - val_loss: 0.3939\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3721 - val_loss: 0.3886\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3716 - val_loss: 0.3730\n",
      "3870/3870 [==============================] - 0s 24us/sample - loss: 0.3702\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 3.6641 - val_loss: 3.0346\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 1.7807 - val_loss: 2.6284\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 1.2173 - val_loss: 1.9414\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.9719 - val_loss: 1.4013\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.8223 - val_loss: 1.0603\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.7281 - val_loss: 0.8395\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6686 - val_loss: 0.7111\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6297 - val_loss: 0.6356\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6025 - val_loss: 0.5856\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5821 - val_loss: 0.5558\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5653 - val_loss: 0.5336\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5507 - val_loss: 0.5186\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5376 - val_loss: 0.5064\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5256 - val_loss: 0.4963\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5152 - val_loss: 0.4873\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5050 - val_loss: 0.4797\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4960 - val_loss: 0.4729\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4878 - val_loss: 0.4666\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4803 - val_loss: 0.4605\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4733 - val_loss: 0.4552\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4673 - val_loss: 0.4498\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4620 - val_loss: 0.4451\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4570 - val_loss: 0.4406\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4525 - val_loss: 0.4366\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4486 - val_loss: 0.4328\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4451 - val_loss: 0.4293\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4418 - val_loss: 0.4265\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4390 - val_loss: 0.4230\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4363 - val_loss: 0.4201\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4339 - val_loss: 0.4173\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4316 - val_loss: 0.4146\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4295 - val_loss: 0.4122\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4276 - val_loss: 0.4096\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4257 - val_loss: 0.4072\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4240 - val_loss: 0.4049\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4219 - val_loss: 0.4036\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4209 - val_loss: 0.4003\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4192 - val_loss: 0.3980\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4178 - val_loss: 0.3959\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4164 - val_loss: 0.3940\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4152 - val_loss: 0.3922\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4139 - val_loss: 0.3908\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4126 - val_loss: 0.3896\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4114 - val_loss: 0.3887\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4102 - val_loss: 0.3884\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4091 - val_loss: 0.3882\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4080 - val_loss: 0.3891\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4068 - val_loss: 0.3892\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4058 - val_loss: 0.3896\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4049 - val_loss: 0.3906\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4039 - val_loss: 0.3921\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4029 - val_loss: 0.3938\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4019 - val_loss: 0.3939\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4011 - val_loss: 0.3952\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4000 - val_loss: 0.3957\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3993 - val_loss: 0.3982\n",
      "3870/3870 [==============================] - 0s 16us/sample - loss: 0.4238\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 3.1750 - val_loss: 4.6157\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 1.1963 - val_loss: 4.8702\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.8313 - val_loss: 4.0757\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.7278 - val_loss: 3.2678\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6764 - val_loss: 2.7249\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6450 - val_loss: 2.4326\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6227 - val_loss: 2.1632\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6048 - val_loss: 2.0070\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5894 - val_loss: 1.8430\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5762 - val_loss: 1.7312\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5638 - val_loss: 1.5851\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5528 - val_loss: 1.4671\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5430 - val_loss: 1.3945\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5335 - val_loss: 1.3061\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5247 - val_loss: 1.2522\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5170 - val_loss: 1.2447\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5096 - val_loss: 1.2114\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5027 - val_loss: 1.2048\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4965 - val_loss: 1.1755\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4904 - val_loss: 1.1565\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4850 - val_loss: 1.1550\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4799 - val_loss: 1.1357\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4751 - val_loss: 1.1219\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4706 - val_loss: 1.1146\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4663 - val_loss: 1.0979\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4622 - val_loss: 1.0970\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4585 - val_loss: 1.0807\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4551 - val_loss: 1.0764\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4518 - val_loss: 1.0604\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4486 - val_loss: 1.0515\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4455 - val_loss: 1.0532\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4429 - val_loss: 1.0396\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4401 - val_loss: 1.0361\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4377 - val_loss: 1.0298\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4353 - val_loss: 1.0167\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4329 - val_loss: 1.0030\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4310 - val_loss: 1.0004\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4288 - val_loss: 1.0006\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4270 - val_loss: 0.9974\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4252 - val_loss: 0.9913\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4235 - val_loss: 0.9910\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4218 - val_loss: 0.9853\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4201 - val_loss: 0.9808\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4184 - val_loss: 0.9792\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4169 - val_loss: 0.9814\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4153 - val_loss: 0.9788\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4140 - val_loss: 0.9773\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4126 - val_loss: 0.9663\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4113 - val_loss: 0.9620\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4100 - val_loss: 0.9569\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4088 - val_loss: 0.9535\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4077 - val_loss: 0.9598\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4063 - val_loss: 0.9472\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4056 - val_loss: 0.9523\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4044 - val_loss: 0.9601\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4033 - val_loss: 0.9563\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4025 - val_loss: 0.9463\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4016 - val_loss: 0.9539\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4008 - val_loss: 0.9518\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3999 - val_loss: 0.9457\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3989 - val_loss: 0.9521\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3980 - val_loss: 0.9351\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3976 - val_loss: 0.9411\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3967 - val_loss: 0.9394\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3960 - val_loss: 0.9399\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3952 - val_loss: 0.9389\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3946 - val_loss: 0.9334\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3939 - val_loss: 0.9389\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3932 - val_loss: 0.9365\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3925 - val_loss: 0.9325\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3918 - val_loss: 0.9439\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3913 - val_loss: 0.9367\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3907 - val_loss: 0.9395\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3901 - val_loss: 0.9421\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3895 - val_loss: 0.9393\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3889 - val_loss: 0.9368\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3884 - val_loss: 0.9471\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3878 - val_loss: 0.9462\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3871 - val_loss: 0.9513\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3866 - val_loss: 0.9488\n",
      "3870/3870 [==============================] - 0s 18us/sample - loss: 0.4003\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 3.7761 - val_loss: 3.4422\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 1.8071 - val_loss: 3.3445\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 1.2114 - val_loss: 2.5594\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 1.0121 - val_loss: 1.8991\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.9109 - val_loss: 1.4479\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.8474 - val_loss: 1.1771\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.8039 - val_loss: 1.0054\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.7716 - val_loss: 0.8930\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.7460 - val_loss: 0.8183\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.7247 - val_loss: 0.7725\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.7063 - val_loss: 0.7429\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6898 - val_loss: 0.7280\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6747 - val_loss: 0.7129\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6605 - val_loss: 0.6993\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6472 - val_loss: 0.6846\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6346 - val_loss: 0.6737\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6226 - val_loss: 0.6628\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6110 - val_loss: 0.6546\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6003 - val_loss: 0.6417\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5898 - val_loss: 0.6337\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5797 - val_loss: 0.6233\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5702 - val_loss: 0.6148\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5609 - val_loss: 0.6052\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5521 - val_loss: 0.5992\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5436 - val_loss: 0.5904\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5353 - val_loss: 0.5858\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5275 - val_loss: 0.5800\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5200 - val_loss: 0.5719\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5129 - val_loss: 0.5663\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5060 - val_loss: 0.5607\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4995 - val_loss: 0.5576\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4934 - val_loss: 0.5524\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4876 - val_loss: 0.5486\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4819 - val_loss: 0.5472\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4769 - val_loss: 0.5418\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4719 - val_loss: 0.5383\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4672 - val_loss: 0.5361\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4628 - val_loss: 0.5350\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4587 - val_loss: 0.5343\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4548 - val_loss: 0.5299\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4511 - val_loss: 0.5280\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4475 - val_loss: 0.5263\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4441 - val_loss: 0.5221\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4411 - val_loss: 0.5212\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4380 - val_loss: 0.5188\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4352 - val_loss: 0.5175\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4325 - val_loss: 0.5133\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4300 - val_loss: 0.5125\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4276 - val_loss: 0.5114\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4253 - val_loss: 0.5109\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4230 - val_loss: 0.5080\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4211 - val_loss: 0.5089\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4192 - val_loss: 0.5069\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4174 - val_loss: 0.5059\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4157 - val_loss: 0.5067\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4140 - val_loss: 0.5077\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4124 - val_loss: 0.5036\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4109 - val_loss: 0.5051\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4096 - val_loss: 0.5026\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4082 - val_loss: 0.5027\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4069 - val_loss: 0.4996\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4055 - val_loss: 0.4972\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4043 - val_loss: 0.4987\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4030 - val_loss: 0.4924\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4020 - val_loss: 0.4934\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4008 - val_loss: 0.4906\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3998 - val_loss: 0.4888\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3988 - val_loss: 0.4875\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3977 - val_loss: 0.4871\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3968 - val_loss: 0.4839\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3958 - val_loss: 0.4837\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3949 - val_loss: 0.4823\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3940 - val_loss: 0.4794\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3931 - val_loss: 0.4864\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3924 - val_loss: 0.4788\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3916 - val_loss: 0.4750\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3909 - val_loss: 0.4852\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3902 - val_loss: 0.4776\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3894 - val_loss: 0.4754\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3888 - val_loss: 0.4733\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3880 - val_loss: 0.4711\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3874 - val_loss: 0.4798\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3867 - val_loss: 0.4761\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3860 - val_loss: 0.4679\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3856 - val_loss: 0.4670\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3850 - val_loss: 0.4645\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3843 - val_loss: 0.4666\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3837 - val_loss: 0.4728\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3832 - val_loss: 0.4747\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3826 - val_loss: 0.4757\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3821 - val_loss: 0.4699\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3815 - val_loss: 0.4700\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3811 - val_loss: 0.4661\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3806 - val_loss: 0.4646\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3801 - val_loss: 0.4659\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3797 - val_loss: 0.4652\n",
      "3870/3870 [==============================] - 0s 16us/sample - loss: 0.3773\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 61us/sample - loss: 1.5411 - val_loss: 1.0746\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.7454 - val_loss: 16.3645\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.7378 - val_loss: 37.4787\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 1.2376 - val_loss: 63.6770\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.9311 - val_loss: 108.7644\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 2.0831 - val_loss: 290.4642\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 5.0396 - val_loss: 732.4059\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 5.9866 - val_loss: 2019.9449\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 11.2595 - val_loss: 4109.5490\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 31.4225 - val_loss: 9851.5857\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 66.2631 - val_loss: 21578.1285\n",
      "3870/3870 [==============================] - 0s 14us/sample - loss: 56.3908\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 1.5363 - val_loss: 0.8588\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.6018 - val_loss: 5.5808\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.5647 - val_loss: 10.7801\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.5451 - val_loss: 13.6496\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.5340 - val_loss: 15.5345\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.5248 - val_loss: 16.6677\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.5177 - val_loss: 16.8004\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.5145 - val_loss: 17.4283\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.5119 - val_loss: 17.4776\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.5084 - val_loss: 18.2617\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.5076 - val_loss: 17.5893\n",
      "3870/3870 [==============================] - 0s 14us/sample - loss: 0.9251\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 2.0587 - val_loss: 49.0452\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 1.1551 - val_loss: 100.3104\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 1.9876 - val_loss: 168.3541\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 2.9393 - val_loss: 271.4086\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 4.2653 - val_loss: 423.3151\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 5.5663 - val_loss: 604.9400\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 9.2415 - val_loss: 889.5397\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 16.9568 - val_loss: 1187.6810\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 24.0802 - val_loss: 1822.7483\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 36.3702 - val_loss: 2469.5935\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 24.9821 - val_loss: 3434.7011\n",
      "3870/3870 [==============================] - 0s 14us/sample - loss: 3.3043\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 1.1879 - val_loss: 36.7615\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.7496 - val_loss: 3.9774\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.4835 - val_loss: 0.4168\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.4230 - val_loss: 0.3870\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.4107 - val_loss: 0.4010\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4014 - val_loss: 0.3756\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3919 - val_loss: 0.3820\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3858 - val_loss: 0.3796\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3904 - val_loss: 0.4301\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3815 - val_loss: 0.3859\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3731 - val_loss: 0.3766\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3738 - val_loss: 0.3776\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3692 - val_loss: 0.3714\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3649 - val_loss: 0.4019\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3618 - val_loss: 0.3698\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3627 - val_loss: 0.3594\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3606 - val_loss: 0.3821\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3567 - val_loss: 0.3595\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3586 - val_loss: 0.3703\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3526 - val_loss: 0.3358\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3490 - val_loss: 0.3421\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3481 - val_loss: 0.3387\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3525 - val_loss: 0.3865\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3457 - val_loss: 0.3308\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3435 - val_loss: 0.3467\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3437 - val_loss: 0.3343\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3465 - val_loss: 0.4021\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3419 - val_loss: 0.3288\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3401 - val_loss: 0.3433\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3405 - val_loss: 0.3339\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3366 - val_loss: 0.3703\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3365 - val_loss: 0.3481\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3355 - val_loss: 0.3235\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3356 - val_loss: 0.3630\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3337 - val_loss: 0.3403\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3328 - val_loss: 0.3244\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3341 - val_loss: 0.3266\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3328 - val_loss: 0.3260\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3316 - val_loss: 0.4142\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3365 - val_loss: 0.3586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3334 - val_loss: 0.3192\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3308 - val_loss: 0.3275\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3275 - val_loss: 0.3895\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3296 - val_loss: 0.3191\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3260 - val_loss: 0.3321\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3277 - val_loss: 0.3472\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3254 - val_loss: 0.3190\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3260 - val_loss: 0.3909\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3235 - val_loss: 0.3235\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3242 - val_loss: 0.3226\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3227 - val_loss: 0.3424\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3219 - val_loss: 0.3137\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3214 - val_loss: 0.3135\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3223 - val_loss: 0.3167\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3193 - val_loss: 0.3150\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3224 - val_loss: 0.3428\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3223 - val_loss: 0.3176\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3235 - val_loss: 0.3732\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3198 - val_loss: 0.3127\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3173 - val_loss: 0.3768\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3279 - val_loss: 0.3085\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3158 - val_loss: 0.3205\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3173 - val_loss: 0.3351\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3156 - val_loss: 0.3105\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3152 - val_loss: 0.3175\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3138 - val_loss: 0.3441\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3138 - val_loss: 0.3110\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3133 - val_loss: 0.3167\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3159 - val_loss: 0.3322\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3123 - val_loss: 0.3152\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3112 - val_loss: 0.3233\n",
      "3870/3870 [==============================] - 0s 16us/sample - loss: 0.3412\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.8330 - val_loss: 0.6831\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4927 - val_loss: 2.0269\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4461 - val_loss: 1.0140\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4199 - val_loss: 0.4765\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4079 - val_loss: 0.4126\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3989 - val_loss: 0.3923\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3907 - val_loss: 0.3967\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3872 - val_loss: 0.4556\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3830 - val_loss: 0.5024\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3790 - val_loss: 0.7108\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3759 - val_loss: 0.6713\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3721 - val_loss: 0.6653\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3717 - val_loss: 0.7884\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3685 - val_loss: 0.9371\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3653 - val_loss: 0.5538\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3666 - val_loss: 0.8892\n",
      "3870/3870 [==============================] - 0s 17us/sample - loss: 0.3795\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.8357 - val_loss: 0.4674\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4668 - val_loss: 2.1631\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5018 - val_loss: 3.1438\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4883 - val_loss: 15.7855\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6305 - val_loss: 6.3034\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4880 - val_loss: 4.7501\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4499 - val_loss: 0.3677\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4030 - val_loss: 0.3769\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3953 - val_loss: 0.3994\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3918 - val_loss: 0.4423\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3918 - val_loss: 0.4179\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3885 - val_loss: 0.4480\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3835 - val_loss: 0.4021\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3811 - val_loss: 0.4240\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3800 - val_loss: 0.3972\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3772 - val_loss: 0.4092\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3737 - val_loss: 0.4185\n",
      "3870/3870 [==============================] - 0s 19us/sample - loss: 0.3627\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 92us/sample - loss: 4.1733 - val_loss: 5.5371\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 2.4124 - val_loss: 7.3047\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 1.6633 - val_loss: 7.9609\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 1.3700 - val_loss: 7.0899\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 1.2064 - val_loss: 5.3485\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 1.0810 - val_loss: 4.1098\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.9881 - val_loss: 3.2674\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.9218 - val_loss: 2.4409\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.8720 - val_loss: 1.8624\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.8356 - val_loss: 1.4703\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.8062 - val_loss: 1.0440\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.7816 - val_loss: 0.8390\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.7617 - val_loss: 0.7547\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.7463 - val_loss: 0.7135\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.7329 - val_loss: 0.6925\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.7209 - val_loss: 0.6820\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.7100 - val_loss: 0.6772\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6997 - val_loss: 0.6731\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6900 - val_loss: 0.6699\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6807 - val_loss: 0.6654\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6720 - val_loss: 0.6597\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6635 - val_loss: 0.6569\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6552 - val_loss: 0.6523\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6473 - val_loss: 0.6450\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6395 - val_loss: 0.6422\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6320 - val_loss: 0.6363\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6246 - val_loss: 0.6317\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6173 - val_loss: 0.6229\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6102 - val_loss: 0.6170\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6031 - val_loss: 0.6087\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5962 - val_loss: 0.6005\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5894 - val_loss: 0.5972\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5827 - val_loss: 0.5886\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5761 - val_loss: 0.5805\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5697 - val_loss: 0.5780\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5631 - val_loss: 0.5769\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5572 - val_loss: 0.5662\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5510 - val_loss: 0.5587\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5450 - val_loss: 0.5514\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5392 - val_loss: 0.5446\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5335 - val_loss: 0.5394\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5279 - val_loss: 0.5328\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5224 - val_loss: 0.5288\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5169 - val_loss: 0.5227\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5117 - val_loss: 0.5146\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5067 - val_loss: 0.5100\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5017 - val_loss: 0.5016\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4970 - val_loss: 0.4981\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4923 - val_loss: 0.4958\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4882 - val_loss: 0.4881\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4839 - val_loss: 0.4819\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4798 - val_loss: 0.4767\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4759 - val_loss: 0.4738\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4723 - val_loss: 0.4673\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4686 - val_loss: 0.4641\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4654 - val_loss: 0.4579\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4622 - val_loss: 0.4538\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4588 - val_loss: 0.4484\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4561 - val_loss: 0.4453\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4533 - val_loss: 0.4433\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4504 - val_loss: 0.4387\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4477 - val_loss: 0.4392\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4454 - val_loss: 0.4339\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4430 - val_loss: 0.4316\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4406 - val_loss: 0.4313\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4384 - val_loss: 0.4272\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4362 - val_loss: 0.4259\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4341 - val_loss: 0.4218\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4321 - val_loss: 0.4201\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4301 - val_loss: 0.4191\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4281 - val_loss: 0.4158\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4265 - val_loss: 0.4160\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4247 - val_loss: 0.4146\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4229 - val_loss: 0.4102\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4215 - val_loss: 0.4096\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4199 - val_loss: 0.4101\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4183 - val_loss: 0.4084\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4168 - val_loss: 0.4059\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4154 - val_loss: 0.4033\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4141 - val_loss: 0.4017\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4128 - val_loss: 0.4009\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4115 - val_loss: 0.4001\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4103 - val_loss: 0.3978\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4091 - val_loss: 0.3968\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4079 - val_loss: 0.3967\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4068 - val_loss: 0.3941\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4055 - val_loss: 0.3918\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4046 - val_loss: 0.3932\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4037 - val_loss: 0.3911\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4027 - val_loss: 0.3904\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4017 - val_loss: 0.3894\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4008 - val_loss: 0.3875\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3998 - val_loss: 0.3862\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3990 - val_loss: 0.3856\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3979 - val_loss: 0.3859\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3972 - val_loss: 0.3838\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3964 - val_loss: 0.3828\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3956 - val_loss: 0.3817\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3947 - val_loss: 0.3812\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3940 - val_loss: 0.3807\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.4137\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 4.3258 - val_loss: 3.0805\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 2.2371 - val_loss: 2.2894\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 1.4703 - val_loss: 1.9711\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 1.1706 - val_loss: 1.6162\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.9949 - val_loss: 1.3014\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.8768 - val_loss: 1.0737\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.7978 - val_loss: 0.9172\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.7448 - val_loss: 0.8210\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.7081 - val_loss: 0.7462\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6816 - val_loss: 0.7032\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6613 - val_loss: 0.6640\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6448 - val_loss: 0.6333\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6310 - val_loss: 0.6139\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6189 - val_loss: 0.5948\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6080 - val_loss: 0.5773\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5982 - val_loss: 0.5673\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5892 - val_loss: 0.5534\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5809 - val_loss: 0.5448\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5732 - val_loss: 0.5351\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5658 - val_loss: 0.5267\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5592 - val_loss: 0.5204\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5527 - val_loss: 0.5146\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5466 - val_loss: 0.5089\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5408 - val_loss: 0.5038\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5353 - val_loss: 0.4990\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5299 - val_loss: 0.4947\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5249 - val_loss: 0.4904\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5200 - val_loss: 0.4863\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5154 - val_loss: 0.4827\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5109 - val_loss: 0.4788\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5065 - val_loss: 0.4745\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5024 - val_loss: 0.4708\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4983 - val_loss: 0.4666\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4943 - val_loss: 0.4628\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4906 - val_loss: 0.4591\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4868 - val_loss: 0.4552\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4834 - val_loss: 0.4518\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4798 - val_loss: 0.4480\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4766 - val_loss: 0.4441\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4734 - val_loss: 0.4408\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4703 - val_loss: 0.4375\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.4674 - val_loss: 0.4346\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4645 - val_loss: 0.4315\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4617 - val_loss: 0.4286\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4591 - val_loss: 0.4260\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4565 - val_loss: 0.4237\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4540 - val_loss: 0.4224\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4515 - val_loss: 0.4193\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4493 - val_loss: 0.4181\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4470 - val_loss: 0.4174\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4449 - val_loss: 0.4175\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4427 - val_loss: 0.4188\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4405 - val_loss: 0.4172\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4387 - val_loss: 0.4197\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4367 - val_loss: 0.4224\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4348 - val_loss: 0.4262\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4330 - val_loss: 0.4261\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4312 - val_loss: 0.4341\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4295 - val_loss: 0.4374\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4277 - val_loss: 0.4414\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4261 - val_loss: 0.4500\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4243 - val_loss: 0.4504\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4229 - val_loss: 0.4639\n",
      "3870/3870 [==============================] - 0s 18us/sample - loss: 0.4329\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 4.5006 - val_loss: 3.9771\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 2.4834 - val_loss: 4.5686\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 1.6793 - val_loss: 4.5299\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 1.3507 - val_loss: 3.8835\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 1.1698 - val_loss: 3.0519\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 1.0496 - val_loss: 2.3645\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.9629 - val_loss: 1.8352\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.8987 - val_loss: 1.5629\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.8510 - val_loss: 1.3598\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.8148 - val_loss: 1.2007\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.7862 - val_loss: 1.0565\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.7632 - val_loss: 0.9718\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.7442 - val_loss: 0.8944\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.7281 - val_loss: 0.8565\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.7144 - val_loss: 0.8270\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.7024 - val_loss: 0.8054\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6918 - val_loss: 0.7839\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6819 - val_loss: 0.7685\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6731 - val_loss: 0.7465\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6645 - val_loss: 0.7321\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6565 - val_loss: 0.7156\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6489 - val_loss: 0.7020\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6416 - val_loss: 0.6885\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6346 - val_loss: 0.6779\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6278 - val_loss: 0.6630\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6212 - val_loss: 0.6523\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6148 - val_loss: 0.6417\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6086 - val_loss: 0.6288\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6026 - val_loss: 0.6175\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5965 - val_loss: 0.6047\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5908 - val_loss: 0.5978\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5854 - val_loss: 0.5865\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5799 - val_loss: 0.5776\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5745 - val_loss: 0.5710\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5695 - val_loss: 0.5605\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5644 - val_loss: 0.5536\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5595 - val_loss: 0.5469\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5548 - val_loss: 0.5407\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5499 - val_loss: 0.5358\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5454 - val_loss: 0.5288\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5409 - val_loss: 0.5235\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5366 - val_loss: 0.5180\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5323 - val_loss: 0.5125\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5281 - val_loss: 0.5084\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5241 - val_loss: 0.5033\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5200 - val_loss: 0.4996\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5163 - val_loss: 0.4946\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5126 - val_loss: 0.4908\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5089 - val_loss: 0.4866\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5054 - val_loss: 0.4837\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5018 - val_loss: 0.4794\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4986 - val_loss: 0.4766\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4952 - val_loss: 0.4729\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4919 - val_loss: 0.4696\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4887 - val_loss: 0.4671\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4855 - val_loss: 0.4646\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4825 - val_loss: 0.4606\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4796 - val_loss: 0.4583\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4768 - val_loss: 0.4555\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4740 - val_loss: 0.4528\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4713 - val_loss: 0.4505\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4687 - val_loss: 0.4475\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4662 - val_loss: 0.4457\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4635 - val_loss: 0.4425\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4613 - val_loss: 0.4410\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4589 - val_loss: 0.4381\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4567 - val_loss: 0.4362\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4545 - val_loss: 0.4341\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4524 - val_loss: 0.4321\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4503 - val_loss: 0.4300\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4482 - val_loss: 0.4287\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4462 - val_loss: 0.4268\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4442 - val_loss: 0.4250\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4424 - val_loss: 0.4234\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4406 - val_loss: 0.4214\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4388 - val_loss: 0.4200\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4371 - val_loss: 0.4186\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4354 - val_loss: 0.4165\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4337 - val_loss: 0.4150\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4322 - val_loss: 0.4144\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4306 - val_loss: 0.4136\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4291 - val_loss: 0.4119\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4276 - val_loss: 0.4106\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4261 - val_loss: 0.4090\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4249 - val_loss: 0.4083\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4235 - val_loss: 0.4078\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4221 - val_loss: 0.4069\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4208 - val_loss: 0.4055\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4196 - val_loss: 0.4049\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4182 - val_loss: 0.4055\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4170 - val_loss: 0.4041\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4157 - val_loss: 0.4035\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4145 - val_loss: 0.4021\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4134 - val_loss: 0.4020\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4122 - val_loss: 0.4021\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4112 - val_loss: 0.4021\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4101 - val_loss: 0.4011\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4091 - val_loss: 0.4014\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4082 - val_loss: 0.4008\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4072 - val_loss: 0.4003\n",
      "3870/3870 [==============================] - 0s 18us/sample - loss: 0.4038\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 1.5791 - val_loss: 4.0226\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.7017 - val_loss: 0.9593\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.6715 - val_loss: 5.2518\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6114 - val_loss: 33.5704\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 1.0816 - val_loss: 0.6314\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5699 - val_loss: 0.5014\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5187 - val_loss: 0.4740\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.4847 - val_loss: 0.4508\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4595 - val_loss: 0.4316\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4411 - val_loss: 0.4201\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4312 - val_loss: 0.4131\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4251 - val_loss: 0.3937\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4195 - val_loss: 0.4006\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.4142 - val_loss: 0.4069\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4107 - val_loss: 0.4042\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.4068 - val_loss: 0.4063\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4028 - val_loss: 0.4064\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3999 - val_loss: 0.4014\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3962 - val_loss: 0.4197\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3928 - val_loss: 0.3701\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.3900 - val_loss: 0.3860\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3886 - val_loss: 0.3777\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3860 - val_loss: 0.4124\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3837 - val_loss: 0.3653\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3811 - val_loss: 0.4222\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3797 - val_loss: 0.3632\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3777 - val_loss: 0.3871\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3758 - val_loss: 0.3901\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3737 - val_loss: 0.3674\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3722 - val_loss: 0.3850\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3705 - val_loss: 0.3895\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.3694 - val_loss: 0.3779\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3679 - val_loss: 0.3575\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.3670 - val_loss: 0.3756\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3655 - val_loss: 0.3948\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.3640 - val_loss: 0.3532\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.3640 - val_loss: 0.3557\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.3623 - val_loss: 0.3592\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3617 - val_loss: 0.3750\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3608 - val_loss: 0.3530\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3607 - val_loss: 0.3585\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3598 - val_loss: 0.3550\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3589 - val_loss: 0.3671\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.3583 - val_loss: 0.3523\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3579 - val_loss: 0.3747\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3575 - val_loss: 0.3727\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3572 - val_loss: 0.3590\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3562 - val_loss: 0.3754\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3566 - val_loss: 0.3480\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3555 - val_loss: 0.3482\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3556 - val_loss: 0.3766\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3547 - val_loss: 0.3510\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3543 - val_loss: 0.3465\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3541 - val_loss: 0.3541\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3534 - val_loss: 0.3436\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3534 - val_loss: 0.3651\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3532 - val_loss: 0.3713\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3525 - val_loss: 0.3544\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3526 - val_loss: 0.3669\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3526 - val_loss: 0.3542\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3517 - val_loss: 0.3440\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3516 - val_loss: 0.3460\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3516 - val_loss: 0.3649\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3515 - val_loss: 0.3438\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.3514 - val_loss: 0.3511\n",
      "3870/3870 [==============================] - 0s 15us/sample - loss: 0.3750\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 1.0946 - val_loss: 2.2170\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5314 - val_loss: 0.7066\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4747 - val_loss: 0.5263\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4455 - val_loss: 0.5381\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.4320 - val_loss: 0.5482\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.4217 - val_loss: 0.6208\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4137 - val_loss: 0.6360\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.4096 - val_loss: 0.7831\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4064 - val_loss: 0.8526\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.4025 - val_loss: 1.0618\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.4005 - val_loss: 1.0540\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3971 - val_loss: 1.0972\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3963 - val_loss: 1.2928\n",
      "3870/3870 [==============================] - 0s 14us/sample - loss: 0.4157\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 1.7594 - val_loss: 29.0153\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.8146 - val_loss: 3.4327\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5825 - val_loss: 0.7523\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5035 - val_loss: 0.5854\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4653 - val_loss: 0.5224\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4444 - val_loss: 0.4838\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.4342 - val_loss: 0.4643\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.4232 - val_loss: 0.4525\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.4175 - val_loss: 0.4439\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.4131 - val_loss: 0.4503\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.4089 - val_loss: 0.4351\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4098 - val_loss: 0.4350\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.4031 - val_loss: 0.4262\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4010 - val_loss: 0.4223\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4011 - val_loss: 0.4158\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3979 - val_loss: 0.4116\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3940 - val_loss: 0.4163\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3925 - val_loss: 0.4071\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3900 - val_loss: 0.4047\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3882 - val_loss: 0.4035\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3861 - val_loss: 0.4025\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3851 - val_loss: 0.3995\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3839 - val_loss: 0.3952\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3826 - val_loss: 0.3964\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3814 - val_loss: 0.3966\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3801 - val_loss: 0.3920\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3790 - val_loss: 0.3967\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.3871 - val_loss: 0.3870\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3773 - val_loss: 0.3807\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3756 - val_loss: 0.3785\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3743 - val_loss: 0.3731\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3754 - val_loss: 0.3734\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3726 - val_loss: 0.3749\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3722 - val_loss: 0.3749\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.3715 - val_loss: 0.3781\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3714 - val_loss: 0.3708\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3695 - val_loss: 0.3717\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3724 - val_loss: 0.3683\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3698 - val_loss: 0.3699\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3684 - val_loss: 0.3632\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3680 - val_loss: 0.3619\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3669 - val_loss: 0.3636\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3681 - val_loss: 0.3572\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3673 - val_loss: 0.3615\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3664 - val_loss: 0.3575\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3652 - val_loss: 0.3554\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3671 - val_loss: 0.3587\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3652 - val_loss: 0.3585\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3643 - val_loss: 0.3606\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3653 - val_loss: 0.3529\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3646 - val_loss: 0.3524\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3632 - val_loss: 0.3516\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3631 - val_loss: 0.3512\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3631 - val_loss: 0.3534\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3625 - val_loss: 0.3545\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3619 - val_loss: 0.3555\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3614 - val_loss: 0.3524\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3607 - val_loss: 0.3536\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3611 - val_loss: 0.3539\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3603 - val_loss: 0.3527\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3611 - val_loss: 0.3497\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3602 - val_loss: 0.3483\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3602 - val_loss: 0.3518\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3592 - val_loss: 0.3473\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3596 - val_loss: 0.3511\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3608 - val_loss: 0.3485\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3589 - val_loss: 0.3484\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3582 - val_loss: 0.3504\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3579 - val_loss: 0.3510\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3579 - val_loss: 0.3473\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3574 - val_loss: 0.3499\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3572 - val_loss: 0.3488\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3576 - val_loss: 0.3498\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3567 - val_loss: 0.3505\n",
      "3870/3870 [==============================] - 0s 15us/sample - loss: 0.3521\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 6.6348 - val_loss: 15.3236\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 5.1730 - val_loss: 10.6401\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 4.0869 - val_loss: 7.4608\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 3.2755 - val_loss: 5.2951\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 2.6661 - val_loss: 3.8418\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 2.2064 - val_loss: 2.8476\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 1.8575 - val_loss: 2.1605\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 1.5914 - val_loss: 1.7036\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 1.3877 - val_loss: 1.3930\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 1.2312 - val_loss: 1.1792\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 1.1102 - val_loss: 1.0355\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 1.0162 - val_loss: 0.9393\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.9428 - val_loss: 0.8772\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.8852 - val_loss: 0.8415\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.8397 - val_loss: 0.8238\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.8035 - val_loss: 0.8108\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.7745 - val_loss: 0.8140\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.7511 - val_loss: 0.8193\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.7322 - val_loss: 0.8213\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.7166 - val_loss: 0.8220\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.7037 - val_loss: 0.8280\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.6928 - val_loss: 0.8382\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.6836 - val_loss: 0.8531\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.6758 - val_loss: 0.8545\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.6689 - val_loss: 0.8690\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.6630 - val_loss: 0.8780\n",
      "3870/3870 [==============================] - 0s 15us/sample - loss: 0.6592\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 6.8205 - val_loss: 30.2651\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 5.1563 - val_loss: 25.8502\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 3.9655 - val_loss: 22.1760\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 3.1073 - val_loss: 19.0660\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 2.4854 - val_loss: 16.4148\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 2.0316 - val_loss: 14.1352\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 1.6988 - val_loss: 12.1601\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 1.4534 - val_loss: 10.4369\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 1.2713 - val_loss: 8.9322\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 1.1353 - val_loss: 7.6132\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 1.0331 - val_loss: 6.4595\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.9557 - val_loss: 5.4503\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.8965 - val_loss: 4.5680\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.8507 - val_loss: 3.8040\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.8148 - val_loss: 3.1444\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.7864 - val_loss: 2.5771\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.7634 - val_loss: 2.0985\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.7446 - val_loss: 1.6986\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.7289 - val_loss: 1.3722\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.7157 - val_loss: 1.1104\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.7043 - val_loss: 0.9097\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.6942 - val_loss: 0.7646\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.6853 - val_loss: 0.6709\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.6773 - val_loss: 0.6243\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.6700 - val_loss: 0.6203\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.6633 - val_loss: 0.6553\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.6571 - val_loss: 0.7265\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.6513 - val_loss: 0.8297\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.6458 - val_loss: 0.9635\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.6406 - val_loss: 1.1247\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.6357 - val_loss: 1.3104\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.6310 - val_loss: 1.5178\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.6266 - val_loss: 1.7440\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.6223 - val_loss: 1.9876\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.6183 - val_loss: 2.2487\n",
      "3870/3870 [==============================] - 0s 14us/sample - loss: 0.6426\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 6.8299 - val_loss: 38.5906\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 4.9999 - val_loss: 26.4697\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 3.7300 - val_loss: 18.4593\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 2.8388 - val_loss: 12.9697\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 2.2067 - val_loss: 9.3330\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 1.7560 - val_loss: 6.8276\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 1.4325 - val_loss: 5.1169\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 1.1990 - val_loss: 3.9383\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 1.0297 - val_loss: 3.1221\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.9068 - val_loss: 2.5394\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.8170 - val_loss: 2.0954\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.7512 - val_loss: 1.7816\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.7029 - val_loss: 1.5304\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.6673 - val_loss: 1.3523\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.6410 - val_loss: 1.2151\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.6214 - val_loss: 1.1267\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.6069 - val_loss: 1.0706\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.5961 - val_loss: 1.0126\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5878 - val_loss: 0.9747\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5814 - val_loss: 0.9536\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5766 - val_loss: 0.9313\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.5728 - val_loss: 0.9138\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.5698 - val_loss: 0.9001\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.5674 - val_loss: 0.8857\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5653 - val_loss: 0.8753\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5636 - val_loss: 0.8721\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5622 - val_loss: 0.8583\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.5609 - val_loss: 0.8539\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5598 - val_loss: 0.8527\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5588 - val_loss: 0.8365\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5578 - val_loss: 0.8265\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.5569 - val_loss: 0.8334\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5560 - val_loss: 0.8399\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.5553 - val_loss: 0.8382\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.5546 - val_loss: 0.8397\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5539 - val_loss: 0.8390\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.5532 - val_loss: 0.8353\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.5526 - val_loss: 0.8309\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.5519 - val_loss: 0.8285\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5513 - val_loss: 0.8159\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5506 - val_loss: 0.8192\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5500 - val_loss: 0.8280\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5495 - val_loss: 0.8136\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5489 - val_loss: 0.8166\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5484 - val_loss: 0.8079\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5479 - val_loss: 0.8038\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5473 - val_loss: 0.8086\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5468 - val_loss: 0.8085\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.5463 - val_loss: 0.8140\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5459 - val_loss: 0.8020\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5454 - val_loss: 0.7924\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5449 - val_loss: 0.7835\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5445 - val_loss: 0.7796\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5440 - val_loss: 0.7824\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5437 - val_loss: 0.7804\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5431 - val_loss: 0.7897\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5428 - val_loss: 0.7916\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5423 - val_loss: 0.8029\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5419 - val_loss: 0.8115\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.5416 - val_loss: 0.8129\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5413 - val_loss: 0.8127\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.5409 - val_loss: 0.8035\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.5405 - val_loss: 0.8046\n",
      "3870/3870 [==============================] - 0s 14us/sample - loss: 0.5460\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 1.2101 - val_loss: 0.7050\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6800 - val_loss: 0.9874\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5868 - val_loss: 0.6704\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5289 - val_loss: 0.6342\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4816 - val_loss: 0.4696\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4561 - val_loss: 0.8970\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4399 - val_loss: 0.5197\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4215 - val_loss: 0.7978\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4109 - val_loss: 1.7586\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4101 - val_loss: 2.5725\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4170 - val_loss: 4.3356\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4275 - val_loss: 3.9567\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4148 - val_loss: 0.9788\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3829 - val_loss: 0.6157\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3723 - val_loss: 0.3922\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3664 - val_loss: 0.4006\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3623 - val_loss: 0.4218\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3593 - val_loss: 0.4008\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3566 - val_loss: 0.3975\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3544 - val_loss: 0.3581\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3509 - val_loss: 0.3657\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3494 - val_loss: 0.3971\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3474 - val_loss: 0.3904\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3452 - val_loss: 0.3534\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3437 - val_loss: 0.4138\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3423 - val_loss: 0.3436\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3408 - val_loss: 0.4104\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3396 - val_loss: 0.3791\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3378 - val_loss: 0.3473\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3362 - val_loss: 0.3696\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3344 - val_loss: 0.3816\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3336 - val_loss: 0.3810\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3328 - val_loss: 0.3349\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3317 - val_loss: 0.4084\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3305 - val_loss: 0.3637\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3296 - val_loss: 0.3248\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3297 - val_loss: 0.3581\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3276 - val_loss: 0.3274\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3269 - val_loss: 0.4014\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3271 - val_loss: 0.3271\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3265 - val_loss: 0.3483\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3249 - val_loss: 0.3206\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3232 - val_loss: 0.4456\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3237 - val_loss: 0.3345\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3228 - val_loss: 0.4326\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3239 - val_loss: 0.3322\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3208 - val_loss: 0.3992\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3193 - val_loss: 0.3350\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3193 - val_loss: 0.3254\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3189 - val_loss: 0.3706\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3183 - val_loss: 0.3687\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3183 - val_loss: 0.3292\n",
      "3870/3870 [==============================] - 0s 15us/sample - loss: 0.3478\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 1.0335 - val_loss: 4.5760\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6158 - val_loss: 1.1300\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5345 - val_loss: 0.6408\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4839 - val_loss: 0.5181\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4511 - val_loss: 0.5344\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4304 - val_loss: 0.5150\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4151 - val_loss: 0.5828\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4047 - val_loss: 0.7289\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3961 - val_loss: 0.6919\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3897 - val_loss: 1.0116\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3846 - val_loss: 0.8852\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3789 - val_loss: 0.9879\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3760 - val_loss: 0.9923\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3718 - val_loss: 1.0313\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3681 - val_loss: 0.8782\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3666 - val_loss: 0.9553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3870/3870 [==============================] - 0s 16us/sample - loss: 0.3820\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 1.3527 - val_loss: 12.6251\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6529 - val_loss: 4.7258\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5475 - val_loss: 0.4558\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4714 - val_loss: 0.4523\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4494 - val_loss: 0.4420\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4318 - val_loss: 0.4293\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4188 - val_loss: 0.4339\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4096 - val_loss: 0.4352\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4019 - val_loss: 0.4328\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3959 - val_loss: 0.4377\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3913 - val_loss: 0.4058\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3855 - val_loss: 0.4190\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3822 - val_loss: 0.3780\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3789 - val_loss: 0.4033\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3759 - val_loss: 0.3706\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3727 - val_loss: 0.3807\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3701 - val_loss: 0.3956\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3683 - val_loss: 0.3752\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3657 - val_loss: 0.3806\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3652 - val_loss: 0.4041\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3615 - val_loss: 0.3907\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3593 - val_loss: 0.3694\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3574 - val_loss: 0.3673\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3550 - val_loss: 0.3737\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3534 - val_loss: 0.3764\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3516 - val_loss: 0.3817\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3501 - val_loss: 0.3700\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3516 - val_loss: 0.3747\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3478 - val_loss: 0.3581\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3463 - val_loss: 0.3513\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3447 - val_loss: 0.3445\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3435 - val_loss: 0.3607\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3419 - val_loss: 0.3710\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3411 - val_loss: 0.3682\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3399 - val_loss: 0.3630\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3387 - val_loss: 0.3469\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3375 - val_loss: 0.3597\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3383 - val_loss: 0.3685\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3362 - val_loss: 0.3609\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3349 - val_loss: 0.3360\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3343 - val_loss: 0.3514\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3326 - val_loss: 0.3610\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3349 - val_loss: 0.3300\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3313 - val_loss: 0.3589\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3303 - val_loss: 0.3335\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3288 - val_loss: 0.3357\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3293 - val_loss: 0.3500\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3273 - val_loss: 0.3410\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3265 - val_loss: 0.3454\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3271 - val_loss: 0.3235\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3248 - val_loss: 0.3224\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3241 - val_loss: 0.3232\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3232 - val_loss: 0.3264\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3234 - val_loss: 0.3345\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3231 - val_loss: 0.3427\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3213 - val_loss: 0.3443\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3199 - val_loss: 0.3197\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3190 - val_loss: 0.3498\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3194 - val_loss: 0.3366\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3190 - val_loss: 0.3349\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3185 - val_loss: 0.3127\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3173 - val_loss: 0.3158\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3161 - val_loss: 0.3396\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3163 - val_loss: 0.3127\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3152 - val_loss: 0.3445\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3172 - val_loss: 0.3112\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3132 - val_loss: 0.3272\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3126 - val_loss: 0.3305\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3119 - val_loss: 0.3363\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3119 - val_loss: 0.3096\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3107 - val_loss: 0.3534\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3105 - val_loss: 0.3094\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3104 - val_loss: 0.3401\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3101 - val_loss: 0.3273\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3104 - val_loss: 0.3029\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3089 - val_loss: 0.3218\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3103 - val_loss: 0.3182\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3080 - val_loss: 0.3256\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3056 - val_loss: 0.3108\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3056 - val_loss: 0.3029\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3061 - val_loss: 0.3033\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3048 - val_loss: 0.3262\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3045 - val_loss: 0.3120\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3039 - val_loss: 0.3019\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3031 - val_loss: 0.3013\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3022 - val_loss: 0.3075\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3013 - val_loss: 0.3111\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3012 - val_loss: 0.3417\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3030 - val_loss: 0.3149\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3004 - val_loss: 0.3140\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3002 - val_loss: 0.2982\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.2990 - val_loss: 0.3470\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.2993 - val_loss: 0.3079\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.2984 - val_loss: 0.2951\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.2980 - val_loss: 0.3153\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3004 - val_loss: 0.2987\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.2975 - val_loss: 0.3159\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3035 - val_loss: 0.2942\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.2968 - val_loss: 0.3144\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.2958 - val_loss: 0.3043\n",
      "3870/3870 [==============================] - 0s 15us/sample - loss: 0.3118\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x63ab45668>, as the constructor either does not set or modifies parameter learning_rate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-145-2e680a8f5da6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrnd_search_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distribs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m rnd_search_cv.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid),\n\u001b[0;32m----> 3\u001b[0;31m                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0;31m# of the params are estimators as well.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0;32m--> 736\u001b[0;31m                 **self.best_params_))\n\u001b[0m\u001b[1;32m    737\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     80\u001b[0m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[1;32m     81\u001b[0m                                \u001b[0;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                                (estimator, name))\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x63ab45668>, as the constructor either does not set or modifies parameter learning_rate"
     ]
    }
   ],
   "source": [
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid),\n",
    "                 callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0033625641252688094, 'n_hidden': 2, 'n_neurons': 42}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.347171781740242"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=keras.optimizers.SGD(lr=0.00336)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=[8]),\n",
    "    keras.layers.Dense(42, activation='relu'),\n",
    "    keras.layers.Dense(42, activation='relu'),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 1.3443 - val_loss: 17.7607\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.6380 - val_loss: 40.4359\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.8049 - val_loss: 2.6793\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4721 - val_loss: 0.5288\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4298 - val_loss: 0.4099\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4141 - val_loss: 0.3766\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4027 - val_loss: 0.3726\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3946 - val_loss: 0.3715\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3879 - val_loss: 0.3794\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3827 - val_loss: 0.3883\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3784 - val_loss: 0.3917\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3747 - val_loss: 0.3958\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3713 - val_loss: 0.3970\n",
      "Epoch 14/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3683 - val_loss: 0.3990\n",
      "Epoch 15/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3668 - val_loss: 0.4036\n",
      "Epoch 16/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3638 - val_loss: 0.4003\n",
      "Epoch 17/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3620 - val_loss: 0.4014\n",
      "Epoch 18/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3594 - val_loss: 0.4022\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, \n",
    "                   validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 18us/sample - loss: 0.3595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3594909813746001"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-154-3b40e07bb81d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrnd_search_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'scorer_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-cbbd136c11f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrnd_search_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    441\u001b[0m         \"\"\"\n\u001b[1;32m    442\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorer_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m             raise ValueError(\"No score function explicitly defined, \"\n\u001b[1;32m    445\u001b[0m                              \u001b[0;34m\"and the estimator doesn't provide one %s\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'scorer_'"
     ]
    }
   ],
   "source": [
    "rnd_search_cv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 10 of Chapter 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train_full, y_train_full), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_full.shape, y_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid, x_train = x_train_full[:5000] / 255., x_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "x_test = x_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0], cmap='binary')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 3, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 28, 28)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x345.6 with 40 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_rows = 4\n",
    "n_cols = 10\n",
    "plt.figure(figsize=(n_cols*1.2, n_rows*1.2))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index+1)\n",
    "        plt.imshow(x_train[index], cmap='binary', interpolation='nearest')\n",
    "        plt.axis('off')\n",
    "        plt.title(y_train[index])\n",
    "plt.subplots_adjust(hspace=0.5, wspace=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExponentialLearningRate(keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.rates.append(K.get_value(self.model.optimizer.lr))\n",
    "        self.losses.append(logs['loss'])\n",
    "        K.set_value(self.model.optimizer.lr, self.model.optimizer.lr * self.factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "expon_lr = ExponentialLearningRate(factor=1.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "55000/55000 [==============================] - 5s 85us/sample - loss: nan - accuracy: 0.5878 - val_loss: nan - val_accuracy: 0.0958\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=1, validation_data=(x_valid, y_valid), callbacks=[expon_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'losses')"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(expon_lr.rates, expon_lr.losses)\n",
    "plt.gca().set_xscale('log')\n",
    "plt.hlines(min(expon_lr.losses), min(expon_lr.rates), max(expon_lr.rates))\n",
    "plt.axis([min(expon_lr.rates), max(expon_lr.rates), 0, expon_lr.losses[0]])\n",
    "plt.xlabel('learning rate')\n",
    "plt.ylabel('losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer=keras.optimizers.SGD(lr=2e-1),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./my_mnist_logs/run_001'"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_index = 1 # increment this at every run\n",
    "run_logdir = os.path.join(os.curdir, \"my_mnist_logs\", \"run_{:03d}\".format(run_index))\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('my_mnist_model.h5', save_best_only=True)\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 5s 84us/sample - loss: 0.2361 - accuracy: 0.9280 - val_loss: 0.1183 - val_accuracy: 0.9664\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 4s 77us/sample - loss: 0.0954 - accuracy: 0.9705 - val_loss: 0.0855 - val_accuracy: 0.9768\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 5s 89us/sample - loss: 0.0642 - accuracy: 0.9796 - val_loss: 0.0822 - val_accuracy: 0.9786\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 4s 81us/sample - loss: 0.0462 - accuracy: 0.9855 - val_loss: 0.0804 - val_accuracy: 0.9770\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.98 - 5s 86us/sample - loss: 0.0333 - accuracy: 0.9894 - val_loss: 0.1907 - val_accuracy: 0.9500\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 4s 78us/sample - loss: 0.0244 - accuracy: 0.9919 - val_loss: 0.0698 - val_accuracy: 0.9828\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 5s 89us/sample - loss: 0.0205 - accuracy: 0.9929 - val_loss: 0.0809 - val_accuracy: 0.9800\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 6s 101us/sample - loss: 0.0153 - accuracy: 0.9949 - val_loss: 0.0841 - val_accuracy: 0.9824\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 6s 101us/sample - loss: 0.0084 - accuracy: 0.9975 - val_loss: 0.0899 - val_accuracy: 0.9788\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 5s 89us/sample - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.0741 - val_accuracy: 0.9844\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 5s 87us/sample - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0729 - val_accuracy: 0.9842\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 4s 79us/sample - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0839 - val_accuracy: 0.9838\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 4s 79us/sample - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0747 - val_accuracy: 0.9858\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 4s 79us/sample - loss: 8.9780e-04 - accuracy: 0.9998 - val_loss: 0.0732 - val_accuracy: 0.9858\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 4s 79us/sample - loss: 3.7406e-04 - accuracy: 1.0000 - val_loss: 0.0771 - val_accuracy: 0.9862\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 4s 79us/sample - loss: 2.2128e-04 - accuracy: 1.0000 - val_loss: 0.0783 - val_accuracy: 0.9860\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 4s 79us/sample - loss: 1.8240e-04 - accuracy: 1.0000 - val_loss: 0.0789 - val_accuracy: 0.9864\n",
      "Epoch 18/100\n",
      "55000/55000 [==============================] - 4s 80us/sample - loss: 1.5978e-04 - accuracy: 1.0000 - val_loss: 0.0800 - val_accuracy: 0.9862\n",
      "Epoch 19/100\n",
      "55000/55000 [==============================] - 4s 80us/sample - loss: 1.4287e-04 - accuracy: 1.0000 - val_loss: 0.0808 - val_accuracy: 0.9862\n",
      "Epoch 20/100\n",
      "55000/55000 [==============================] - 4s 80us/sample - loss: 1.2992e-04 - accuracy: 1.0000 - val_loss: 0.0812 - val_accuracy: 0.9860\n",
      "Epoch 21/100\n",
      "55000/55000 [==============================] - 4s 80us/sample - loss: 1.2116e-04 - accuracy: 1.0000 - val_loss: 0.0816 - val_accuracy: 0.9860\n",
      "Epoch 22/100\n",
      "55000/55000 [==============================] - 4s 80us/sample - loss: 1.1251e-04 - accuracy: 1.0000 - val_loss: 0.0820 - val_accuracy: 0.9862\n",
      "Epoch 23/100\n",
      "55000/55000 [==============================] - 4s 80us/sample - loss: 1.0464e-04 - accuracy: 1.0000 - val_loss: 0.0826 - val_accuracy: 0.9866\n",
      "Epoch 24/100\n",
      "55000/55000 [==============================] - 4s 81us/sample - loss: 9.8997e-05 - accuracy: 1.0000 - val_loss: 0.0833 - val_accuracy: 0.9864\n",
      "Epoch 25/100\n",
      "55000/55000 [==============================] - 4s 80us/sample - loss: 9.3607e-05 - accuracy: 1.0000 - val_loss: 0.0837 - val_accuracy: 0.9864\n",
      "Epoch 26/100\n",
      "55000/55000 [==============================] - 4s 81us/sample - loss: 8.8776e-05 - accuracy: 1.0000 - val_loss: 0.0839 - val_accuracy: 0.9864\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=100,\n",
    "                   validation_data = (x_valid, y_valid),\n",
    "                   callbacks=[early_stopping_cb, checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.0692 - accuracy: 0.9806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06917384602149541, 0.9806]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_best = keras.models.load_model('my_mnist_model.h5')\n",
    "model_best.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"my_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./my_logs/run_2020_09_15-16_32_29'"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-cd3fca9093761bc\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-cd3fca9093761bc\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
